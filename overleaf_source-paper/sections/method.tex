\section{Method}
\label{sec:method}
% Furkan, Onur

In this work, we compare the annotation schemes in two versions of the UD Turkish BOUN treebank, versions 2.8 and 2.11.
We ask a large language model to recover the surface form (i.e., original text) of a sentence given the lemmas, parts of speech, and morphological features in its annotation.
Since models like ChatGPT~\cite{openai2021gpt35} are able to handle natural language and associate linguistic feature signals with linguistic material, we opted to use as natural a language as possible in the prompts.
In this respect, we converted the annotations in the treebank into natural language sentences.
For instance, the \texttt{POS} tag of a word being \texttt{NOUN} is represented with the phrase \textit{it is a noun} in the prompt.

The important point in guiding a large language model is deciding on a prompt that enables the model to generate the desired output.
We tested alternative prompts and arrived at the one that is formed of three parts.
The prompt first gives the description of the task and what follows in the following paragraphs.
In this description, we also included explanations to the abstraction of copula form to ensure that LLM understands the prompts better.

After the description, we provide an example question and answer to guide the model in a one-shot setting.
The example includes providing the token count of the sentence, and each token's lemma, part-of-speech tag and morphological features, if any, in separate lines.
Morphological feature annotations are ordered as they would surface in a token, as applies to Turkish morphology.
As the annotations of the tokens are fed to the model through these natural language sentences, we inform the LLM that its task is recovering the \textit{surface form} of the given sentence and we give the answer for the example sentence.
In the last part of the prompt, we provide the annotations of a new sentence in the same manner and ask the LLM to output the original sentence.

For each sentence, its annotations in the treebank versions 2.8 and 2.11 are queried as described above.
The sentence output by the LLM for each version is compared with the original sentence.
This process is repeated for all the sentences in the set and accuracy scores for both treebanks are computed.
The comparison is done by the sequence matching algorithm of Python~\cite{python}.
We use the \texttt{SequenceMatcher} module of the \texttt{difflib} library to get a ratio of matching sequences in the two texts, the original sentence and the output sentence.
After comparing each sentence in this way, we calculate an average score of accuracy for the entire set.

Table~\ref{tab:prompt} shows a prompt to reconstruct the Turkish sentence ``Tepelere sisler indi." (``Fogs descended on the hills."). The preamble includes a one-shot example (the sentence ``Me\c{s}rutiyetin ilanından önceki siyasi faaliyetlere kat{\i}ld{\i}.'' - ``He/she participated in the activities prior to the constitutional monarchy.'') to illustrate the expected behavior. The \conllu\ annotation of the example sentence is given in Table~\ref{tab:conll}.
The prompt only provides the annotations of the tokens to the large language model for the model to generate the surface forms of the sentence. The prompts are automatically generated by a script using a template.

\begin{table*}
\begin{tabular}{| p{6in} |}
\hline
\\
\texttt{The following sentences detail linguistic features of a Turkish sentence with lemmas, parts of speech and morphological features given for each token. Lemma "y" represents the overt copula in Turkish and surfaces as "i".}\\\\[-1mm]
\texttt{The sentence has 7 tokens.}\\\\[-1mm]
\texttt{1st token's lemma is "meşrutiyet", its part of speech is proper noun, its case is genitive, its number is singular number, and its person is third person.
2nd token's lemma is "ilan", its part of speech is noun, its person is third person, its number is singular number, its possessor's person is third person, its possessor's number is singular number, and its case is ablative.
3rd token's lemma is "önceki", and its part of speech is adjective.
4th token's lemma is "siyasi", and its part of speech is adjective.
5th token's lemma is "faaliyet", its part of speech is noun, its person is third person, its number is plural number, and its case is dative.
6th token's lemma is "kat", its part of speech is verb, its voice is reflexive voice, its polarity is positive, its tense is past tense, its aspect is perfect aspect, its person is third person, its number is singular number, and its evidentiality is first hand.
7th token's lemma is ".", and its part of speech is punctuation.}\\\\[-1mm]

\texttt{Your task is to find the surface form of the sentence. For example, your answer for the previous parse should be:} \\\\[-1mm]
\texttt{"Meşrutiyetin ilanından önceki siyasi faaliyetlere katıldı."}\\\\[-1mm]
\texttt{Now, analyze the following test example and try to find the surface form of the sentence. It has 4 tokens. Please include all the tokens in your answer in order. Output only the surface form without any explanations or sentences in English.}\\\\[-1mm]

\texttt{1st token's lemma is "tepe", its part of speech is noun, its person is third person, its number is plural number, and its case is dative.
2nd token's lemma is "sis", its part of speech is noun, its person is third person, its number is plural number, and its case is nominative.
3rd token's lemma is "in", its part of speech is verb, its polarity is positive, its tense is past tense, its aspect is perfect aspect, its person is third person, its number is singular number, and its evidentiality is first hand.
4th token's lemma is "...", and its part of speech is punctuation.}\\\\
\hline
\end{tabular}
\caption{\label{tab:prompt} A prompt for LLMs to reconstruct the surface form of a Turkish sentence given the annotations of its lemmas.}
\end{table*}
\renewcommand{\arraystretch}{1.3}
\begin{table*}
    \centering
    \begin{tabularx}{\textwidth}{|c|c|c|c|X|}
    \hline
    \textbf{ID} & \textbf{Form} & \textbf{Lemma} & \textbf{POS} & \multicolumn{1}{c}{\textbf{Feats}} \\
    \hline    \hline
    1 & Meşrutiyetin & meşrutiyet & PROPN & \seqsplit{Case=Gen\ \textbar\ Number=Sing \textbar\ Person=3} \\    \hline
    2 & ilanından & ilan & NOUN & Case=Abl \textbar\ Number=Sing   \textbar\ Number[psor]=Sing \textbar\ Person=3 \textbar\  Person[psor]=3 \\    \hline
    3 & önceki & önceki & ADJ & \multicolumn{1}{c|}{\textbf{---}} \\    \hline
    4 & siyasi & siyasi & ADJ & \multicolumn{1}{c|}{\textbf{---}} \\ \hline
    5 & faaliyetlere & faaliyet & NOUN & Case=Dat \textbar\ Number=Plur \textbar\ Person=3 \\    \hline
    6 & katıldı & kat & VERB & Aspect=Perf \textbar\ Evident=Fh \textbar Number=Sing \textbar Person=3 \textbar\ Polarity=Pos \textbar\ Tense=Past \textbar\ Voice=Rfl \\    \hline
    7 & \Large \textperiodcentered & \Large \textperiodcentered & PUNCT & \multicolumn{1}{c|}{\textbf{---}}\\
    \hline
    \end{tabularx}
    \caption{\label{tab:conll} The \conllu\ annotation, with only relevant columns, of the example sentence in the prompt.}
\end{table*}

In the preliminary experiments we observed that the models may output some English explanations about the recovered sentence and some filtering steps are needed to remove these explanations. For these, we used heuristic filtering functions.
