python3 llm-approach/do_error_analysis-annotation.py -d llm-approach/experiment_outputs/eventual_experiment/poe_GPT-3.5-Turbo-20231015223903
# Model: poe_GPT-3.5-Turbo
# v2.8 ratio: 0.538818632943813
# v2.11 ratio: 0.551784856731231
python3 llm-approach/do_error_analysis-annotation.py -d llm-approach/experiment_outputs/eventual_experiment/poe_GPT-4-20231015231246
# Model: poe_GPT-4
# v2.8 ratio: 0.7366720516962844
# v2.11 ratio: 0.7536348949919225
python3 llm-approach/do_error_analysis-annotation.py -d llm-approach/experiment_outputs/eventual_experiment/poe_Claude-2-100k-20231016083251
# Model: poe_Claude-2-100k
# v2.8 ratio: 0.6574355690731551
# v2.11 ratio: 0.7046582359532576
python3 llm-approach/do_error_analysis-annotation.py -d llm-approach/experiment_outputs/eventual_experiment/poe_Claude-instant-100k-20231016001050
# Model: poe_Claude-instant-100k
# v2.8 ratio: 0.5753161517528413
# v2.11 ratio: 0.6015687530014406